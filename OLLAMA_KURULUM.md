# Ollama Kurulum Rehberi - ÃœCRETSÄ°Z Yerel AI

Ollama tamamen Ã¼cretsizdir ve bilgisayarÄ±nÄ±zda yerel olarak Ã§alÄ±ÅŸÄ±r. Ä°nternet baÄŸlantÄ±sÄ± olmadan da kullanabilirsiniz!

## ğŸš€ HÄ±zlÄ± Kurulum (Windows)

1. **Ollama'yÄ± Ä°ndirin:**
   - https://ollama.ai adresine gidin
   - "Download for Windows" butonuna tÄ±klayÄ±n
   - Ä°ndirilen `.exe` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±p kurun

2. **Model Ä°ndirin:**
   Kurulumdan sonra PowerShell veya CMD'de ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
   ```
   ollama pull llama3.2
   ```
   Veya daha kÃ¼Ã§Ã¼k ve hÄ±zlÄ± bir model:
   ```
   ollama pull llama3.2:1b
   ```

3. **Ollama'yÄ± BaÅŸlatÄ±n:**
   Ollama genelde otomatik baÅŸlar, ama kontrol etmek iÃ§in:
   ```
   ollama serve
   ```

4. **ChatCore.AI'yi Ollama'ya AyarlayÄ±n:**
   - `backend\.env` dosyasÄ±nÄ± aÃ§Ä±n
   - `AI_PROVIDER=OLLAMA` olarak deÄŸiÅŸtirin
   - (Ollama varsayÄ±lan olarak `http://localhost:11434` adresinde Ã§alÄ±ÅŸÄ±r)

5. **Backend'i Yeniden BaÅŸlatÄ±n:**
   - Backend penceresini kapatÄ±n
   - `baslat.bat` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n

## âœ… Test

TarayÄ±cÄ±da bir soru sorun, artÄ±k Ollama kullanÄ±yor olmalÄ±!

## ğŸ“ Ã–nerilen Modeller

- **llama3.2:1b** - En hÄ±zlÄ±, kÃ¼Ã§Ã¼k model (~1GB)
- **llama3.2** - Dengeli, orta boy (~2GB)
- **llama3.1:8b** - Daha gÃ¼Ã§lÃ¼ ama daha yavaÅŸ (~4.7GB)
- **mistral** - Ä°yi performans (~4GB)
- **phi3** - KÃ¼Ã§Ã¼k ama etkili (~2.3GB)

## ğŸ’¡ Avantajlar

- âœ… Tamamen Ã¼cretsiz
- âœ… Ä°nternet baÄŸlantÄ±sÄ± gerektirmez (model indirildikten sonra)
- âœ… Verileriniz hiÃ§bir yere gÃ¶nderilmez (gizlilik)
- âœ… Sorgu limiti yok
- âœ… API key gerektirmez

## âš ï¸ Dezavantajlar

- Ä°lk model indirme biraz uzun sÃ¼rebilir
- BilgisayarÄ±nÄ±zÄ±n RAM'ine baÄŸlÄ± olarak yavaÅŸ olabilir
- BÃ¼yÃ¼k modeller iÃ§in disk alanÄ± gerektirir

