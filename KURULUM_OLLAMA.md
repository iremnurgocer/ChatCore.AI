# Ollama Kurulum Rehberi

## ğŸ“‹ Gereksinimler

- **Ä°ÅŸletim Sistemi**: Windows, macOS, Linux
- **RAM**: En az 8GB (16GB Ã¶nerilir)
- **Disk AlanÄ±**: 2-4GB (model boyutuna gÃ¶re)
- **Ä°nternet BaÄŸlantÄ±**: Ä°lk kurulum iÃ§in gerekli (model indirme)

## ğŸš€ HÄ±zlÄ± Kurulum

### Windows

```batch
kurulum_ollama.bat
```

### macOS / Linux

```bash
chmod +x kurulum_ollama.sh
./kurulum_ollama.sh
```

## ğŸ“ AdÄ±m AdÄ±m Kurulum

### 1. Ollama'yi Ä°ndir ve Kur

#### Windows
1. https://ollama.ai adresine gidin
2. "Download for Windows" butonuna tÄ±klayÄ±n
3. Ä°ndirilen `.exe` dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve kurulum sihirbazÄ±nÄ± takip edin
4. Kurulum tamamlandÄ±ktan sonra Ollama otomatik olarak baÅŸlar

#### macOS
```bash
brew install ollama
```

veya

1. https://ollama.ai adresine gidin
2. "Download for macOS" butonuna tÄ±klayÄ±n
3. Ä°ndirilen `.dmg` dosyasÄ±nÄ± aÃ§Ä±n ve Ollama'yÄ± Applications klasÃ¶rÃ¼ne sÃ¼rÃ¼kleyin
4. Uygulamalar klasÃ¶rÃ¼nden Ollama'yÄ± baÅŸlatÄ±n

#### Linux
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. Model Ä°ndir

Terminal/Command Prompt aÃ§Ä±n ve ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
ollama pull llama3.2
```

**Alternatif Modeller:**
- `ollama pull llama3.2` - Orta boyut (2GB), hÄ±zlÄ±, Ã¶nerilen
- `ollama pull llama3` - BÃ¼yÃ¼k boyut (4GB), daha iyi kalite
- `ollama pull mistral` - KÃ¼Ã§Ã¼k boyut (1GB), Ã§ok hÄ±zlÄ±
- `ollama pull codellama` - Kod iÃ§in optimize

**Model Ä°ndirme SÃ¼resi:** 5-15 dakika (internet hÄ±zÄ±nÄ±za baÄŸlÄ±)

### 3. Ollama Servisinin Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Kontrol Et

TarayÄ±cÄ±nÄ±zda ÅŸu adrese gidin:
```
http://localhost:11434
```

BaÅŸarÄ±lÄ± ise "Ollama is running" mesajÄ± gÃ¶rÃ¼rsÃ¼nÃ¼z.

**Veya terminal'de:**
```bash
ollama list
```

Bu komut indirdiÄŸiniz modelleri listeler.

### 4. Proje YapÄ±landÄ±rmasÄ±

`backend/.env` dosyasÄ±nÄ± aÃ§Ä±n ve ÅŸu ayarlarÄ± yapÄ±n:

```env
AI_PROVIDER=OLLAMA
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
```

**Not:** `OLLAMA_MODEL` deÄŸerini indirdiÄŸiniz modele gÃ¶re deÄŸiÅŸtirin.

## âœ… Kurulumu Test Et

### 1. Backend'i BaÅŸlat
```batch
# Windows
baslat.bat

# macOS/Linux
./baslat.sh
```

### 2. Test Komutu
Terminal'de:
```bash
curl http://localhost:8000/api/status
```

BaÅŸarÄ±lÄ± ise `"ai_provider": "OLLAMA"` gÃ¶rÃ¼rsÃ¼nÃ¼z.

### 3. Chat ArayÃ¼zÃ¼nden Test
1. http://localhost:8501 adresine gidin
2. GiriÅŸ yapÄ±n (admin / 1234)
3. Herhangi bir soru sorun
4. AI yanÄ±t vermelidir

## ğŸ”§ Sorun Giderme

### Ollama baÅŸlamÄ±yor
**Windows:**
- Services panelinden "Ollama" servisinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin
- GÃ¶rev yÃ¶neticisinden "ollama" process'inin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin

**macOS/Linux:**
```bash
ollama serve
```

### Model indirme hatasÄ±
- Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin
- Disk alanÄ±nÄ±zÄ± kontrol edin (en az 5GB boÅŸ alan)
- FarklÄ± bir model deneyin (Ã¶rn: `mistral` daha kÃ¼Ã§Ã¼k)

### Backend Ollama'ya baÄŸlanamÄ±yor
- Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol edin: `curl http://localhost:11434`
- `OLLAMA_BASE_URL` deÄŸerini kontrol edin
- Firewall Ollama'yÄ± engellemiyor mu kontrol edin

### YanÄ±t Ã§ok yavaÅŸ
- Daha kÃ¼Ã§Ã¼k bir model deneyin (`mistral` veya `llama3.2:1b`)
- RAM'inizi kontrol edin (en az 8GB Ã¶nerilir)
- GPU varsa Ollama GPU kullanÄ±mÄ±nÄ± etkinleÅŸtirin

## ğŸ“Š Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model | Boyut | RAM | HÄ±z | Kalite |
|-------|-------|-----|-----|--------|
| mistral | 4.1GB | 8GB | â­â­â­â­â­ | â­â­â­â­ |
| llama3.2 | 2.0GB | 8GB | â­â­â­â­ | â­â­â­â­ |
| llama3 | 4.7GB | 16GB | â­â­â­ | â­â­â­â­â­ |
| codellama | 3.8GB | 16GB | â­â­â­ | â­â­â­â­ |

## ğŸ¯ Avantajlar

âœ… **Tamamen Ãœcretsiz** - Sorgu limiti yok  
âœ… **Gizlilik** - Verileriniz dÄ±ÅŸarÄ± gitmiyor  
âœ… **Offline Ã‡alÄ±ÅŸma** - Ä°nternet gerektirmez (model indirildikten sonra)  
âœ… **SÄ±nÄ±rsÄ±z KullanÄ±m** - AylÄ±k/gsÃ¼nlÃ¼k limit yok  

## âš ï¸ Dezavantajlar

âš ï¸ **Model Ä°ndirme Gerekli** - Ä°lk kurulumda 2-4GB indirme  
âš ï¸ **Yerel Kaynak Gerektirir** - BilgisayarÄ±nÄ±zÄ±n gÃ¼cÃ¼ne baÄŸlÄ±  
âš ï¸ **Azure/OpenAI kadar hÄ±zlÄ± olmayabilir** - CPU'ya baÄŸlÄ±  

## ğŸ“š Ek Kaynaklar

- [Ollama Resmi DokÃ¼mantasyon](https://ollama.ai/docs)
- [Model Listesi](https://ollama.ai/library)
- [GitHub Repository](https://github.com/ollama/ollama)

